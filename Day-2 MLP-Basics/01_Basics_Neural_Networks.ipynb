{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "01. Basics_Neural Networks.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntyr5m8-DOlr"
      },
      "source": [
        "# Basics of MLP\n",
        "- Objective: create vanilla neural networks (i.e., Multilayer perceptrons) for simple regression/classification tasks with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JEsMD0wDOlt"
      },
      "source": [
        "## MLP Structures\n",
        "- Each MLP model is consisted of one input layer, several hidden layers, and one output layer\n",
        "- Number of neurons in each layer is not limited\n",
        "<img src=\"http://cs231n.github.io/assets/nn1/neural_net.jpeg\" style=\"width: 300px\"/>\n",
        "<br>\n",
        "<center>**MLP with one hidden layer**</center>\n",
        "- Number of input neurons: 3\n",
        "- Number of hidden neurons: 4\n",
        "- Number of output neurons: 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS2o_gxnDOlu"
      },
      "source": [
        "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" style=\"width: 500px\"/>\n",
        "<br>\n",
        "<center>**MLP with two hidden layers**</center>\n",
        "- Number of input neurons: 3\n",
        "- Number of hidden neurons: (4, 4)\n",
        "- Number of output neurons: 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3miFUZWRDOlu"
      },
      "source": [
        "## MLP for Regression tasks\n",
        "- When the target (**y**) is continuous (real)\n",
        "- For loss function and evaluation metric, mean squared error (MSE) is commonly used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWHO2tIxDOlv"
      },
      "source": [
        "from keras.datasets import boston_housing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_5E8_VcDOlw"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsWNL_nUDOlw"
      },
      "source": [
        "### Dataset Description\n",
        "- Boston housing dataset has total 506 data instances (404 training & 102 test)\n",
        "- 13 attributes (features) to predict \"the median values of the houses at a location\"\n",
        "- Doc: https://keras.io/datasets/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7N88vnvDOlx",
        "outputId": "25e41e99-afc4-4603-8d8b-473c16d09a5e"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 13)\n",
            "(102, 13)\n",
            "(404,)\n",
            "(102,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9W-wf1dDOlx"
      },
      "source": [
        "### 1. Creating a model\n",
        "- Keras model object can be created with Sequential class\n",
        "- At the outset, the model is empty per se. It is completed by **'adding'** additional layers and compilation\n",
        "- Doc: https://keras.io/models/sequential/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2RLIEESDOlx"
      },
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jq0ojbNDOly"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_to0wX81DOly"
      },
      "source": [
        "### 1-1. Adding layers\n",
        "- Keras layers can be **added** to the model\n",
        "- Adding layers are like stacking lego blocks one by one\n",
        "- Doc: https://keras.io/layers/core/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB61Vqx8DOly"
      },
      "source": [
        "from keras.layers import Activation, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE90ZsqHDOlz"
      },
      "source": [
        "# This is equivalent to the above code block\n",
        "model.add(Dense(10, input_shape = (13,), activation = 'sigmoid')) #13 - ist he number of columns you have in the I/p\n",
        "model.add(Dense(10, activation = 'sigmoid'))\n",
        "model.add(Dense(10, activation = 'sigmoid'))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkp2y9uNDOlz"
      },
      "source": [
        "### 1-2. Model compile\n",
        "- Keras model should be \"compiled\" prior to training\n",
        "- Types of loss (function) and optimizer should be designated\n",
        "    - Doc (optimizers): https://keras.io/optimizers/\n",
        "    - Doc (losses): https://keras.io/losses/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMZ9jRtcDOlz"
      },
      "source": [
        "from keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF0RIWhlDOl0",
        "outputId": "1c196d5e-78ba-498e-8ee3-754a33976df5"
      },
      "source": [
        "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dm3TGvODOl0"
      },
      "source": [
        "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfMt8mi5DOl0"
      },
      "source": [
        "### Summary of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fNlLormDOl0",
        "outputId": "b85b5017-4066-4239-cbb2-e5fb33772903"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_28 (Dense)             (None, 10)                140       \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 371\n",
            "Trainable params: 371\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNx9IvVBDOl1"
      },
      "source": [
        "### 2. Training\n",
        "- Training the model with training data provided"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm0FLG0vDOl1",
        "outputId": "32e173bf-3770-41c8-a3c5-5977ec914016"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1,validation_split = 0.20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 84.2908 - mse: 84.2908 - val_loss: 86.7639 - val_mse: 86.7639\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.2939 - mse: 84.2939 - val_loss: 86.3189 - val_mse: 86.3189\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3558 - mse: 84.3558 - val_loss: 86.4533 - val_mse: 86.4533\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3054 - mse: 84.3054 - val_loss: 88.0571 - val_mse: 88.0571\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.6427 - mse: 84.6427 - val_loss: 84.7970 - val_mse: 84.7970\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.5463 - mse: 84.5463 - val_loss: 87.1106 - val_mse: 87.1106\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.5265 - mse: 84.5265 - val_loss: 85.5719 - val_mse: 85.5719\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.6608 - mse: 84.6608 - val_loss: 86.3212 - val_mse: 86.3212\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.6420 - mse: 84.6420 - val_loss: 85.9144 - val_mse: 85.9144\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.4785 - mse: 84.4785 - val_loss: 85.9997 - val_mse: 85.9997\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.7145 - mse: 84.7145 - val_loss: 87.3664 - val_mse: 87.3664\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3880 - mse: 84.3880 - val_loss: 85.6909 - val_mse: 85.6909\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3349 - mse: 84.3349 - val_loss: 88.2280 - val_mse: 88.2280\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.1919 - mse: 84.1919 - val_loss: 85.1278 - val_mse: 85.1278\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 84.8228 - mse: 84.8228 - val_loss: 85.8354 - val_mse: 85.8354\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.5741 - mse: 84.5741 - val_loss: 86.9785 - val_mse: 86.9785\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3945 - mse: 84.3945 - val_loss: 86.9262 - val_mse: 86.9262\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.6665 - mse: 84.6665 - val_loss: 86.1036 - val_mse: 86.1036\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.3207 - mse: 84.3207 - val_loss: 88.0488 - val_mse: 88.0488\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 84.7071 - mse: 84.7071 - val_loss: 90.5030 - val_mse: 90.5030\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.5815 - mse: 84.5815 - val_loss: 86.7016 - val_mse: 86.7016\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.5460 - mse: 84.5460 - val_loss: 85.6378 - val_mse: 85.6378\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 84.3591 - mse: 84.3591 - val_loss: 87.5506 - val_mse: 87.5506\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3757 - mse: 84.3757 - val_loss: 85.0332 - val_mse: 85.0332\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.5241 - mse: 84.5241 - val_loss: 88.4288 - val_mse: 88.4288\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.5319 - mse: 84.5319 - val_loss: 88.0260 - val_mse: 88.0260\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.5787 - mse: 84.5787 - val_loss: 86.3923 - val_mse: 86.3923\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.4892 - mse: 84.4892 - val_loss: 85.5900 - val_mse: 85.5900\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.7355 - mse: 84.7355 - val_loss: 88.3083 - val_mse: 88.3083\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 85.1636 - mse: 85.1636 - val_loss: 87.3479 - val_mse: 87.3479\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.5090 - mse: 84.5090 - val_loss: 87.9795 - val_mse: 87.9795\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.5926 - mse: 84.5926 - val_loss: 86.7401 - val_mse: 86.7401\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3740 - mse: 84.3740 - val_loss: 86.1463 - val_mse: 86.1463\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.2368 - mse: 84.2368 - val_loss: 86.9456 - val_mse: 86.9456\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.6749 - mse: 84.6749 - val_loss: 86.7275 - val_mse: 86.7275\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3675 - mse: 84.3675 - val_loss: 88.2565 - val_mse: 88.2565\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.3603 - mse: 84.3603 - val_loss: 87.6857 - val_mse: 87.6857\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.7658 - mse: 84.7658 - val_loss: 85.4632 - val_mse: 85.4632\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.5489 - mse: 84.5489 - val_loss: 86.7570 - val_mse: 86.7570\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.1990 - mse: 84.1990 - val_loss: 86.2886 - val_mse: 86.2886\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.2213 - mse: 84.2213 - val_loss: 87.6165 - val_mse: 87.6165\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.2073 - mse: 84.2073 - val_loss: 87.1818 - val_mse: 87.1818\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.6018 - mse: 84.6018 - val_loss: 86.0231 - val_mse: 86.0231\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.5363 - mse: 84.5363 - val_loss: 85.2876 - val_mse: 85.2876\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 85.0524 - mse: 85.0524 - val_loss: 87.1353 - val_mse: 87.1353\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3138 - mse: 84.3138 - val_loss: 86.5211 - val_mse: 86.5211\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 85.0214 - mse: 85.0214 - val_loss: 86.0936 - val_mse: 86.0936\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.6503 - mse: 84.6503 - val_loss: 86.8214 - val_mse: 86.8214\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.2707 - mse: 84.2707 - val_loss: 87.3198 - val_mse: 87.3198\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.2547 - mse: 84.2547 - val_loss: 86.9443 - val_mse: 86.9443\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.4100 - mse: 84.4100 - val_loss: 87.3813 - val_mse: 87.3813\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3494 - mse: 84.3494 - val_loss: 86.2118 - val_mse: 86.2118\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.4163 - mse: 84.4163 - val_loss: 86.0451 - val_mse: 86.0451\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.8488 - mse: 84.8488 - val_loss: 85.5074 - val_mse: 85.5074\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.7598 - mse: 84.7598 - val_loss: 87.0872 - val_mse: 87.0872\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3270 - mse: 84.3270 - val_loss: 86.1633 - val_mse: 86.1633\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 84.2633 - mse: 84.2633 - val_loss: 87.7009 - val_mse: 87.7009\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3114 - mse: 84.3114 - val_loss: 88.9543 - val_mse: 88.9543\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.5976 - mse: 84.5976 - val_loss: 87.3129 - val_mse: 87.3129\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.4862 - mse: 84.4862 - val_loss: 86.5071 - val_mse: 86.5071\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.4174 - mse: 84.4174 - val_loss: 86.5613 - val_mse: 86.5613\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.5457 - mse: 84.5457 - val_loss: 86.0287 - val_mse: 86.0287\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.5525 - mse: 84.5525 - val_loss: 85.8084 - val_mse: 85.8084\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.6222 - mse: 84.6222 - val_loss: 86.6948 - val_mse: 86.6948\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.6444 - mse: 84.6444 - val_loss: 86.3227 - val_mse: 86.3227\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.2865 - mse: 84.2865 - val_loss: 87.6310 - val_mse: 87.6310\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.4333 - mse: 84.4333 - val_loss: 89.2209 - val_mse: 89.2209\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 85.2678 - mse: 85.2678 - val_loss: 86.0227 - val_mse: 86.0227\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.5952 - mse: 84.5952 - val_loss: 87.9121 - val_mse: 87.9121\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 84.2679 - mse: 84.2679 - val_loss: 87.4203 - val_mse: 87.4203\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.3090 - mse: 84.3090 - val_loss: 86.8350 - val_mse: 86.8350\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 84.3236 - mse: 84.3236 - val_loss: 87.2708 - val_mse: 87.2708\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.6057 - mse: 84.6057 - val_loss: 87.3446 - val_mse: 87.3446\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3925 - mse: 84.3925 - val_loss: 87.2045 - val_mse: 87.2045\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.4535 - mse: 84.4535 - val_loss: 86.7502 - val_mse: 86.7502\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.2466 - mse: 84.2466 - val_loss: 89.6154 - val_mse: 89.6154\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.8572 - mse: 84.8572 - val_loss: 86.6835 - val_mse: 86.6835\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.4551 - mse: 84.4551 - val_loss: 87.0274 - val_mse: 87.0274\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.5731 - mse: 84.5731 - val_loss: 87.6922 - val_mse: 87.6922\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 84.3274 - mse: 84.3274 - val_loss: 86.7491 - val_mse: 86.7491\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.3455 - mse: 84.3455 - val_loss: 87.9952 - val_mse: 87.9952\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.5706 - mse: 84.5706 - val_loss: 86.4880 - val_mse: 86.4880\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.5728 - mse: 84.5728 - val_loss: 86.1015 - val_mse: 86.1015\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3461 - mse: 84.3461 - val_loss: 87.7852 - val_mse: 87.7852\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.4355 - mse: 84.4355 - val_loss: 86.7739 - val_mse: 86.7739\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 84.4702 - mse: 84.4702 - val_loss: 88.2928 - val_mse: 88.2928\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.4062 - mse: 84.4062 - val_loss: 86.7918 - val_mse: 86.7918\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.3636 - mse: 84.3636 - val_loss: 87.0180 - val_mse: 87.0180\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.5763 - mse: 84.5763 - val_loss: 86.9524 - val_mse: 86.9524\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 84.5813 - mse: 84.5813 - val_loss: 87.4903 - val_mse: 87.4903\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.3728 - mse: 84.3728 - val_loss: 88.1372 - val_mse: 88.1372\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.3404 - mse: 84.3404 - val_loss: 86.4286 - val_mse: 86.4286\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.5196 - mse: 84.5196 - val_loss: 85.5625 - val_mse: 85.5625\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 84.3581 - mse: 84.3581 - val_loss: 86.0903 - val_mse: 86.0903\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.3449 - mse: 84.3449 - val_loss: 87.1150 - val_mse: 87.1150\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.2078 - mse: 84.2078 - val_loss: 87.0374 - val_mse: 87.0374\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.5139 - mse: 84.5139 - val_loss: 86.4083 - val_mse: 86.4083\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.3042 - mse: 84.3042 - val_loss: 86.4945 - val_mse: 86.4945\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 84.4266 - mse: 84.4266 - val_loss: 87.0784 - val_mse: 87.0784\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 84.2631 - mse: 84.2631 - val_loss: 88.2013 - val_mse: 88.2013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4b76884790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXsaBLGxDOl1"
      },
      "source": [
        "### 3. Evaluation\n",
        "- Keras model can be evaluated with evaluate() function\n",
        "- Evaluation results are contained in a list\n",
        "    - Doc (metrics): https://keras.io/metrics/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8Hvx8nMDOl1",
        "outputId": "d748f99b-c384-40a6-fa11-e89d43a0af0f"
      },
      "source": [
        "results = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 3ms/step - loss: 83.2236 - mse: 83.2236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ewOnrs8DOl2",
        "outputId": "d9c2b5cb-6299-481f-88f9-d22cdc2b1c17"
      },
      "source": [
        "print(model.metrics_names)     # list of metric names the model is employing\n",
        "print(results)                 # actual figure of metrics computed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'mse']\n",
            "[83.22356414794922, 83.22356414794922]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnw5fMgFDOl2",
        "outputId": "734dba30-9196-464a-c58f-c8fe6c58120e"
      },
      "source": [
        "print('loss: ', results[0])\n",
        "print('mse: ', results[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:  83.22356414794922\n",
            "mse:  83.22356414794922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWnhb2UCDOl2"
      },
      "source": [
        "## MLP for classification tasks\n",
        "- When the target (**y**) is discrete (categorical)\n",
        "- For loss function, cross-entropy is used and for evaluation metric, accuracy is commonly used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2uvyXf5DOl2"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wasPmfCDOl2"
      },
      "source": [
        "whole_data = load_breast_cancer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_KjA_EqDOl3"
      },
      "source": [
        "X_data = whole_data.data\n",
        "y_data = whole_data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NULPKIXmDOl3"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.3, random_state = 7) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SAttWAsDOl3"
      },
      "source": [
        "### Dataset Description\n",
        "- Breast cancer dataset has total 569 data instances (212 malign, 357 benign instances)\n",
        "- 30 attributes (features) to predict the binary class (M/B)\n",
        "- Doc: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRz6VrNLDOl4",
        "outputId": "6e3d599a-113c-429f-a85e-8be52de7a7f9"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(398, 30)\n",
            "(171, 30)\n",
            "(398,)\n",
            "(171,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7g5UTmkDOl4"
      },
      "source": [
        "### 1. Creating a model\n",
        "- Same with regression model at the outset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa-Q5lgNDOl4"
      },
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aQ3j_A1DOl4"
      },
      "source": [
        "model = Sequential() #S caps do not forget! "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH3vi48HDOl4"
      },
      "source": [
        "### 1-1. Adding layers\n",
        "- Keras layers can be **added** to the model\n",
        "- Adding layers are like stacking lego blocks one by one\n",
        "- It should be noted that as this is a classification problem, sigmoid layer (softmax for multi-class problems) should be added\n",
        "- Doc: https://keras.io/layers/core/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEHwDnjqDOl5"
      },
      "source": [
        "# Keras model with two hidden layer with 10 neurons each \n",
        "model.add(Dense(10, input_shape = (30,)))    # Input layer => input_shape should be explicitly designated\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZf4919kDOl5"
      },
      "source": [
        "# This is equivalent to the above code block\n",
        "model.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
        "model.add(Dense(10, activation = 'sigmoid'))\n",
        "model.add(Dense(10, activation = 'sigmoid'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c36hxjWcDOl5"
      },
      "source": [
        "### 1-2. Model compile\n",
        "- Keras model should be \"compiled\" prior to training\n",
        "- Types of loss (function) and optimizer should be designated\n",
        "    - Doc (optimizers): https://keras.io/optimizers/\n",
        "    - Doc (losses): https://keras.io/losses/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T2dJyjZDOl5"
      },
      "source": [
        "from keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGAkMpzdDOl5",
        "outputId": "f379025e-6513-4d57-d19b-80bef5cfc35e"
      },
      "source": [
        "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Wk8hADDOl6"
      },
      "source": [
        "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0_uGISADOl6"
      },
      "source": [
        "### Summary of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcQN_MtdDOl7",
        "outputId": "d2ec0362-387d-49c8-e3f1-8dbbf9158531"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_32 (Dense)             (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 541\n",
            "Trainable params: 541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXCmcedhDOl8"
      },
      "source": [
        "### 2. Training\n",
        "- Training the model with training data provided"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFsDNtFLDOl8",
        "outputId": "65cd356f-3b53-4492-df96-fb05bcd12e8e"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size = 50, epochs = 100, )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 2ms/step - loss: 0.7290 - accuracy: 0.4088\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7211 - accuracy: 0.4026\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7153 - accuracy: 0.3881\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7057 - accuracy: 0.4075\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.4048\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.3806\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.6054\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.6133\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.6163\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.6099\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.6222\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.6034\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.6228\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.5988\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.5941\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5827\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.6111\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6215\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.6022\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.6316\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.5993\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.6119\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.6169\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.6092\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.6188\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.6195\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6692 - accuracy: 0.6118\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.6018\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.5903\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.6105\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.5734\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.5892\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.6077\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6288\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.5915\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.6179\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.6124\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.6148\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.6157\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.6087\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.6153\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.6072\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6655 - accuracy: 0.6185\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6645 - accuracy: 0.6210\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6667 - accuracy: 0.6158\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.5960\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.5957\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.5776\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.6151\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.6454\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6371\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.6134\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5925\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.6128\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.5979\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.6061\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.5874\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.5914\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.6022\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.6000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.6290\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.5945\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.6247\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.6215\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.6440\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.5981\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.6343\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.5914\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.5933\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.6034\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.6203\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.6262\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.5895\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.6131\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.6186\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6263\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.6092\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.5926\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.5973\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.6117\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.5947\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.6207\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.5873\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.5989\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.5832\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.6189\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.6113\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.6010\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.6241\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.5920\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6147\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6094\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.5901\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.6196\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.6165\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.6222\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6345\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.6066\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.6117\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.5979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4b78380c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgBbe2MsDOl8"
      },
      "source": [
        "### 3. Evaluation\n",
        "- Keras model can be evaluated with evaluate() function\n",
        "- Evaluation results are contained in a list\n",
        "    - Doc (metrics): https://keras.io/metrics/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-1ORR5SDOl8",
        "outputId": "e6a4b501-c15b-400a-9f98-d0014187396d"
      },
      "source": [
        "results = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 1s 3ms/step - loss: 0.6396 - accuracy: 0.6784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqWtCyzEDOl8",
        "outputId": "296d93ce-5616-478d-95b0-fab0c97c0421"
      },
      "source": [
        "print(model.metrics_names)     # list of metric names the model is employing\n",
        "print(results)                 # actual figure of metrics computed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'accuracy']\n",
            "[0.6396194696426392, 0.6783625483512878]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEZ5OI8kDOl9",
        "outputId": "310d0efe-3af9-4352-bf72-62e9e2838797"
      },
      "source": [
        "print('loss: ', results[0])\n",
        "print('accuracy: ', results[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:  0.6396194696426392\n",
            "accuracy:  0.6783625483512878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK4xupAZDOl9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}